# Установка и запуск

Есть несколько вариантов, в порядке возрастания сложности.

После завершения установки и запуска, в браузере нужно открыть http://127.0.0.1:4990/ - 
если страница открылась, приложение было успешно запущено.

## 1. Запуск через внешние инструменты
### Portablesource
* Необходимо загрузить приложение для запуска https://github.com/portablesource/portablesource
* Открыть приложение, дождаться завершения установки необходимых компонентов.
* На главном экране приложения нажать кнопку "Установить по ссылке/имени".
* Ввести адрес проекта https://github.com/illian64/llm-translate
* Найти проект в пункте "Установленные" и нажать "Запустить".

**Известные проблемы.**
Могут не установиться зависимости, и сервис не сможет запуститься.

Решение (Windows):
* нужно перейти в папку `путь_к_portablesource\repos\llm-translate`, 
* открыть для редактирования файл запуска `start_llm-translate.bat`
* между строками `cd /d "%repo_path%"` и `"%python_exe%" main.py` вставить строку `"%python_exe%" -m pip install -r requirements.txt`
* запустить, дождаться старта приложения, после этого добавленную строку можно убрать


### Pinokio
* Необходимо загрузить приложение для запуска и следовать инструкциям https://pinokio.co/docs/#/?id=install

## Docker
Необходимо загрузить код (или клонировать через GIT) https://github.com/illian64/llm-translate

В данный момент Docker-образ не опубликован, но `Dockerfile` для создания контейнера добавлен в проект.
Нужно перейти в загруженную ранее папку проекта и запустить `docker compose up --build`
Для Linux-систем возможно потребуется установить NVIDIA Toolkit (чтобы обеспечить доступ к видеокарте из контейнера)
https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html

Также для внешних сервисов - таких, как LM Studio, нужно будет в папке настроек поменять адреса доступа с локальных на
http://host.docker.internal:port

## Загрузка и проекта и запуск через CLI / IDE
Этот вариант для тех, кто уже сталкивался с запуском Python-проектов, поэтому все шаги уже должны быть понятны.

Для запуска требуется Python, CUDA (опционально, для некоторых плагинов), установленные Python-зависимости (venv, conda...).
Запуск через
* `python -m uvicorn main:app --reload --host=0.0.0.0 --port=4990 --log-level=info --log-config=resources/log_config.yaml`
* или `__main__` метод в `main.py` (в корне проекта).
